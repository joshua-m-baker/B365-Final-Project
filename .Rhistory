<<<<<<< HEAD
?pnorm
pnorm(3/10, mean = -5, sd = 10, lower.tail = FALSE)
pnorm(5/10, mean = -5, sd = 10, lower.tail = FALSE)
pnorm(0, mean = -5, sd = 10, lower.tail = FALSE)
1 - pnorm(1/2, mean = -5, sd = 10, lower.tail=FALSE)
pnorm(1/2, mean = -5, sd = 10)
pnorm(1.2)
pnorm(1/2)
pnorm(1)
1 - pnorm(1)
pnorm(1.2)-pnorm(.2)
pnorm(1)-pnorm(-1)
1-pnorm(10)+P(3/5)
1-pnorm(10)+pnorm(3/5)
qnorm(.25,10,15)
#1.
data <- scan("http://mypage.iu.edu/~mtrosset/StatInfeR/Data/sample771.dat")
boxplot(data)
boxplot(data, main = "P1 Boxplot")
qqnorm(data)
qqline(data)
boxplot(data, main = "P1 E)")
qqnorm(data, main = "P1 F)")
qqline(data)
density(data)
plot(density(data))
plot(density(data), main = "P1 G)")
boxplot(data, main = "P1 E)")
qqnorm(data, main = "P1 F)")
qqline(data)
plot(density(data), main = "P1 G)")
#2.
data <- c(88,76,84,64,60,64,60,64,68,74,
68,68,72,76,72,52,72,64,60,56,
72,88,80,76,64,72,60,76,88,72,
64,60,60,72,92,80,72,64,68)
boxplot(data, main = "P2 E)")
qqnorm(data, main = "P2 F)")
qqline(data)
plot(density(data), main = "P2 G)")
#3
data <- scan("http://mypage.iu.edu/~mtrosset/StatInfeR/Data/sample773.dat")
data
typeof(data)
#3
data <- as.data.frame(scan("http://mypage.iu.edu/~mtrosset/StatInfeR/Data/sample773.dat"))
typeof(data)
data
#3
data <- matrix(scan("http://mypage.iu.edu/~mtrosset/StatInfeR/Data/sample773.dat"),ncol=4)
data
data <- fread("http://mypage.iu.edu/~mtrosset/StatInfeR/Data/sample773.dat")
#3
library(data.table)
data <- fread("http://mypage.iu.edu/~mtrosset/StatInfeR/Data/sample773.dat")
#3
install.packages(data.table)
#3
install.packages('data.table')
#3
install.packages('data.table')
library(data.table)
data <- fread("http://mypage.iu.edu/~mtrosset/StatInfeR/Data/sample773.dat")
data
boxplot(data)
boxplot(data, main = "P3 A)")
x = numerical(4)
x1 = rnorm(10)
x1
x1 = rnorm(10)
x2 = rnorm(10)
x3 = rnorm(10)
x4 = rnorm(10)
data.normal = c(x1,x2,x3,x4)
data.normal
data.normal = matrix(c(x1,x2,x3,x4), nrow = 10)
data.normal
boxplot(data.normal)
boxplot(data, main = "P3 A)")
boxplot(data.normal)
#4
data <- fread("http://mypage.iu.edu/~mtrosset/StatInfeR/Data/sample776.dat")
#4
data <- c(90,90,89,88,85,85,84,82,82,82,
81,81,81,80,79,79,78,76,75,74,
72,71,70,66,65,63,62,62,61,59,
58,58,57,56,56,53,48,44,40,35,33)
plot(density(data), main = "P6 A)")
?lapply
x = replicate(25, urn.model())
urn.model <- function(){
urn = c(1,1,1,1,2,5,5,10,10,10)
x = sample(urn, 40, replace = TRUE)
return(sum(x))
}
x = replicate(25, urn.model())
x
plot(density(data))
plot(density(x))
#1.
data <- scan("http://mypage.iu.edu/~mtrosset/StatInfeR/Data/sample771.dat")
boxplot(data, main = "P1 E)")
qqnorm(data, main = "P1 F)")
qqnorm(data, main = "P1 F)")
qqnorm(data, main = "P1 F)")
boxplot(data, main = "P1 E)")
boxplot(data, main = "P1 E)")
qqnorm(data, main = "P1 F)")
qqline(data)
plot(density(data), main = "P1 G)")
#2.
data <- c(88,76,84,64,60,64,60,64,68,74,
68,68,72,76,72,52,72,64,60,56,
72,88,80,76,64,72,60,76,88,72,
64,60,60,72,92,80,72,64,68)
boxplot(data, main = "P2 E)")
qqnorm(data, main = "P2 F)")
qqline(data)
plot(density(data), main = "P2 G)")
data <- fread("http://mypage.iu.edu/~mtrosset/StatInfeR/Data/sample773.dat")
boxplot(data, main = "P3 A)")
boxplot(data.normal)
data.normal = matrix(c(x1,x2,x3,x4), nrow = 10)
boxplot(data.normal)
#4
data <- c(90,90,89,88,85,85,84,82,82,82,
81,81,81,80,79,79,78,76,75,74,
72,71,70,66,65,63,62,62,61,59,
58,58,57,56,56,53,48,44,40,35,33)
plot(density(data), main = "P6 A)")
urn.model <- function(){
urn = c(1,1,1,1,2,5,5,10,10,10)
x = sample(urn, 40, replace = TRUE)
return(sum(x))
}
x = replicate(25, urn.model())
plot(density(x))
boxplot(x)
plot(density(x))
library(data.table)
data <- fread("http://mypage.iu.edu/~mtrosset/StatInfeR/Data/sample773.dat")
boxplot(data, main = "P3 A)")
x1 = rnorm(10)
x2 = rnorm(10)
x3 = rnorm(10)
x4 = rnorm(10)
data.normal = matrix(c(x1,x2,x3,x4), nrow = 10)
boxplot(data.normal)
boxplot(data.normal, main="P3 B)")
#4
data <- c(90,90,89,88,85,85,84,82,82,82,
81,81,81,80,79,79,78,76,75,74,
72,71,70,66,65,63,62,62,61,59,
58,58,57,56,56,53,48,44,40,35,33)
plot(density(data), main = "P6 A)")
urn.model <- function(){
urn = c(1,1,1,1,2,5,5,10,10,10)
x = sample(urn, 40, replace = TRUE)
return(sum(x))
}
x = replicate(25, urn.model())
boxplot(x)
plot(density(x))
boxplot(x)
plot(density(x))
plot(density(x),main="P7 B)")
1- pnorm(.83)
sum = 0
for(i in 1:20){
sum += 5
}
for(i in 1:20){
sum = sum + 5
}
sum
1-pnorm(105,100,.5)
?pnorm
1-pnorm(105,100,sqrt(5))
1-pnorm(105,100
)
1-pnorm(105,mean = 5, .5)
1-pnorm(105,mean = 5, sd = .5)
1-pnorm(105,100,sqrt(5))
instal.packages('rmarkdown')
install.packages('rmarkdown')
1 - P(Z<= .83) # = .20
1 - pnorm(.83) #= .20
source('C:/Users/Joshua/Dropbox/Stats-S320/HW9/HW9.R')
#8.6.6
1-pnorm(50, .01/400)
#8.6.6
1-pnorm(50,.01, .01/400)
#8.6.6
1-pnorm(50,.01, .1/20)
.1*.1
#8.6.6
1-pnorm(50,4, .1*20)
400*.01
20*.1
20*20
#8.6.6
1-pnorm(50,mean=4,sd=2)
#8.6.6
1-pnorm(0,mean=.01,sd=.1)
#8.6.6
1-pnorm(0,mean=4,sd=2)
plot(pnorm(4,2))
plot(qnorm(4,2))
#actual cdf: equal probability for each atomic outcome in {1,2,3,4,5,6}
plot.ecdf((1:6))
#compared with the *actual* cdf.
curve(pnorm(x,mean = 2, sd = 2),add=T)
curve(pnorm(x,mean = 2, sd = 2),add=T, col = 'red')
#From a normal distribution
set.seed(123)
samp <- rnorm(200)
boxplot(samp)
z <- rnorm(100)
cs <- rchisq(100, df=3)
qqnorm(z)
qqline(z)
qqnorm(cs)
qqline(cs)
#Kernel density estimators
plot(density(z))
40*4.6
14.64*40
#8.6.6
#mu = .01, sigma^2 = .01, sigma = .1
# ex = n*mu = 4, sd = sqrt(n)*sigma
1-pnorm(0,mean=4,sd=2)
1-pnorm((0-.01)/.1)
#B)
1-pnorm((0-0)/.5)
1-pnorm((0-4)/2)
#B)
1-pnorm((0-0)/2)
1-pnorm(0, mean=0, sd = 2)
#C)
1-pnorm((20-4)/2)
#C)
1-pnorm((20-4)/2)
#D)
1-pnorm((20-0)/10)
9.6.2
data <- c(1.864, 1.457, 1.848, 5.853, 2.201, 1.207, 0.044, 4.969, 3.249,3.355, 6.631, 2.153, 1.011, 2.378, 2.829, 3.852, 1.675, 2.644,2.05, 3.47)
mean(data)
mean(data)*(19/20)
length(data)
sum(data)/length(data)
1-prorm((2.737-2)/sqrt(4))
1-pnorm((2.737-2)/sqrt(4))
#C)
1-pnorm((20-4)/2)
#C)
pnorm((20-4)/2)
2-.737
pbinom(1.263)
pbinom(1.263,20,2)
1-pnorm(105, 100, 5)
1-pnorm(105, 100, sqrt(5)
)
scale <- function(col){
mi = min(col)
ma = max(col)
for(i in 1:length(col)){
col[i] = (col[i]-mi)/(ma-mi)
}
return(col)
}
library('data.table')
library('caret')
library('dummies')
car.data = fread('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data')
credit.data =  fread('https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data')
car.data[car.data=='?'] = NA
credit.data[credit.data == '?'] = NA
#Manually fix some data
credit.data$V2 = as.numeric(credit.data$V2)
credit.data$V14 = as.numeric(credit.data$V14)
car.data = na.omit(car.data)
credit.data = na.omit(credit.data)
credit.data = data.frame(credit.data)
credit.data.classes = credit.data[,ncol(credit.data)]
credit.data = dummy.data.frame(credit.data[,c(-1, -ncol(credit.data))], drop=FALSE)
credit.data = cbind(credit.data, class = credit.data.classes)
credit.data
scale <- function(col){
mi = min(col)
ma = max(col)
for(i in 1:length(col)){
col[i] = (col[i]-mi)/(ma-mi)
}
return(col)
}
for(i in 1:ncol(credit.data)){
col = credit.data[,i]
if(is.numeric(col)){
credit.data[,i] = scale(col)
}
}
credit.data
college <- scan(file.choose('college.txt'))
college <- scan('college.txt')
college <- scan(file.choose())
plot(college)
boxplot(college)
qqnorm(college)
qqline(college)
ozone <- scan(file.choose())
qqnorm(ozone)
qqline(ozone)
qqnorm(college)
qqline(college)
plot(density(college))
plot(density(rnorm(100)))
plot(density(college))
summary(college)
head(college)
c = scale(college)
plot(density(college))
plot(density(c))
summary(c)
plot(density(college))
c = college[college!=max(college)]
summary(c)
plot(density(college))
plot(density(c))
plot(density(college))
qqnorm(ozone)
qqline(ozone)
boxplot(college)
boxplot(college)
boxplot(college, xlab = 'Salary', main = "College Boxplot")
qqnorm(college, main = "College Qq-plot")
qqline(college)
qqnorm(college, main = "College qq-plot")
qqline(college)
summary(college)
length(college)
mean(college)
m = mean(college)
t.test(college, mu = m)
t.test(college, mu = 57,000)
t.test(college, mu = 57,000)
t.test(college, mu = 0)
t.test(college, mu = 57000)
t.test(college, mu = 57000, alternative = 'l')
m = mean(college)
m
length(college)
mean(college)
var(college)
var(college)
length(college)
sd(college)
m = mean(college)
l = length(college)
v = var(college)
s = sd(college)
#B)
#H0 = u <= 57,000     H1 = u > 57,000
#reject if H1 << 57,000
#alpha = .05
u=57000
p = (m-u)/(s/sqrt(n))
n=340
p = (m-u)/(s/sqrt(n))
p
1-pnorm(1.91)
?t.test
t.test(college, mu = 57000, alternative = "greater")
t.test(college, mu = 57000, alternative = 'l')
t.test(college, mu = 57000)
t.test(college, mu = 68000)
t.test(college)
boxplot(ozone)
plot(density(ozone))
qqnorm(ozone)
qqline(ozone)
t.test(ozone)
summary(ozone)
head(ozone)
boxplot(ozone)
qqnorm(ozone)
qqline(ozone)
plot(density(ozone))
qqnorm(ozone)
qqline(ozone)
qqnorm(college, main = "College qq-plot")
qqline(college)
t.test(ozone)
#95 percent confidence interval:
#  36.06240 48.19622
t.test(ozone, mu=50)
#95 percent confidence interval:
#  36.06240 48.19622
t.test(ozone, mu=50, alternative = 'l')
#95 percent confidence interval:
#  36.06240 48.19622
t.test(ozone, mu=50, alternative = 'g')
#install.packages('mice')
#library('mice')
#setwd('C:\\Users\\Joshua\\Documents\\GitHub\\B365-Final-Project')
library("caret")
=======
#Contruct Centroids
# indices <- c(1:nrow(data))
# count = 1
# for (i in sample(indices, k, replace = FALSE)){
#   centroids[count] <- data[i,]
#   count <- count+1
# }
centroids = as.data.frame(matrix(rnorm(k*dimen),nrow = k, ncol = dimen))
ctau= .Machine$integer.max
while(ctau >= tau){
#assign centroids to data
for (i in 1:nrow(data)){
data$centroids[i] <- min.dist(data[i,1:ncol(data)-1], distFun, centroids)
}
#update centroids
old_cent <- centroids
for (i in 1:k){
counter = 0
sum = matrix(0, nrow = 1, ncol = dimen)
for (j in 1:nrow(data)){
if (data[j,]$centroids == i){
counter = counter +1
sum <- sum + centroids[i,]
}
}
centroids[i,] = sum/counter
}
centroid_distances = centroids - old_cent
ctau = (1/k) * sum((centroid_distances)^2)
}
return(centroids)
}
mydata=matrix(rnorm(100*2), ncol=2)
mydata[1:50,1]=mydata[1:50,1]+3
mydata[1:50,2]=mydata[1:50,2]-4
KMean(mydata, Euclidean.Dist, 2, 10)
Euclidean.Dist <- function(matrix1, matrix2){
differences <- matrix1-matrix2
diffsqr = differences * differences
return(sqrt(sum(diffsqr)))
}
min.dist <- function(entry, distFun, centroids){
distance = .Machine$integer.max
index = 1
for (i in 1:nrow(centroids)){
held = distFun(entry, centroids[i,])
if(held < distance){
distance = held
index = i
}
}
return(index)
}
KMean <- function(data, distFun, k, tau){
data <- as.data.frame(data)
dimen = ncol(data)
cbind(data, centroids = NA)
centroids <- as.data.frame(matrix(rnorm(k*dimen), nrow = k , ncol = dimen))
old_cent <- centroids
#Contruct Centroids
# indices <- c(1:nrow(data))
# count = 1
# for (i in sample(indices, k, replace = FALSE)){
#   centroids[count] <- data[i,]
#   count <- count+1
# }
centroids = as.data.frame(matrix(rnorm(k*dimen),nrow = k, ncol = dimen))
ctau= .Machine$integer.max
while(ctau >= tau){
#assign centroids to data
for (i in 1:nrow(data)){
data$centroids[i] <- min.dist(data[i,1:ncol(data)-1], distFun, centroids)
}
#update centroids
old_cent <- centroids
for (i in 1:k){
counter = 0
sum = matrix(0, nrow = 1, ncol = dimen)
for (j in 1:nrow(data)){
if (data[j,]$centroids == i){
counter = counter +1
sum <- sum + centroids[i,]
}
}
centroids[i,] = sum/counter
}
centroid_distances = centroids - old_cent
ctau = (1/k) * sum((centroid_distances)^2)
}
print(data)
return(centroids)
}
mydata=matrix(rnorm(100*2), ncol=2)
mydata[1:50,1]=mydata[1:50,1]+3
mydata[1:50,2]=mydata[1:50,2]-4
KMean(mydata, Euclidean.Dist, 2, 10)
Euclidean.Dist <- function(matrix1, matrix2){
differences <- matrix1-matrix2
diffsqr = differences * differences
return(sqrt(sum(diffsqr)))
}
min.dist <- function(entry, distFun, centroids){
distance = .Machine$integer.max
index = 1
for (i in 1:nrow(centroids)){
held = distFun(entry, centroids[i,])
if(held < distance){
distance = held
index = i
}
}
return(index)
}
KMean <- function(data, distFun, k, tau){
dimen = ncol(data)
cbind(data, centroids = NA)
centroids <- as.data.frame(matrix(rnorm(k*dimen), nrow = k , ncol = dimen))
old_cent <- centroids
#Contruct Centroids
# indices <- c(1:nrow(data))
# count = 1
# for (i in sample(indices, k, replace = FALSE)){
#   centroids[count] <- data[i,]
#   count <- count+1
# }
centroids = as.data.frame(matrix(rnorm(k*dimen),nrow = k, ncol = dimen))
ctau= .Machine$integer.max
while(ctau >= tau){
#assign centroids to data
for (i in 1:nrow(data)){
data$centroids[i] <- min.dist(data[i,1:ncol(data)-1], distFun, centroids)
}
#update centroids
old_cent <- centroids
for (i in 1:k){
counter = 0
sum = matrix(0, nrow = 1, ncol = dimen)
for (j in 1:nrow(data)){
if (data[j,]$centroids == i){
counter = counter +1
sum <- sum + centroids[i,]
}
}
centroids[i,] = sum/counter
}
centroid_distances = centroids - old_cent
ctau = (1/k) * sum((centroid_distances)^2)
}
return(centroids)
}
mydata=matrix(rnorm(100*2), ncol=2)
mydata[1:50,1]=mydata[1:50,1]+3
mydata[1:50,2]=mydata[1:50,2]-4
KMean(as.data.frame(mydata), Euclidean.Dist, 2, 10)
data <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data", header = FALSE)
A <- data[,-length(data)]
A.pca <- prcomp(A)
summary(A.pca)
pairs(A.pca$x[,1:2])
plot(A.pca, type = "l")
setwd("C:/Users/Greg/B365-Final-Project")
setwd('C:\\Users\\Joshua\\Documents\\GitHub\\B365-Final-Project')
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
data.test <- subset(data.test,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
setwd("C:/Users/Greg/B365-Final-Project")
setwd("C:/Users/Greg/B365-Final-Project")
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
data.test <- subset(data.test,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
View(data.test)
View(data.train)
training_classes = data.train[,2]
data.train <- subset(data.train,select = -c(target))
View(data.train)
training_size = length(data.train)
total_data = rbind(data.train, data.test)
pca <- prcomp(total_data)
summary(total_data)
col_means = colMeans(total_data,na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
summary(total_data)
pca <- prcomp(total_data)
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
pca
pca.loadings
summary(pca)
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
training_classes = data.train[,1]
data.train <- subset(data.train,select = -c(target))
training_size = length(data.train)
total_data = rbind(data.train, data.test)
col_means = colMeans(total_data,na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
summary(total_data)
# PCA Stuff
pca <- prcomp(total_data)
summary(pca)
View(data.test)
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
View(data.test)
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
test_ids = data.test$id
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
training_classes = data.train$target
data.train <- subset(data.train,select = -c(target))
training_size = nrow(data.train)
total_data = rbind(data.train, data.test)
col_means = colMeans(total_data,na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
#summary(total_data)
# PCA Stuff
pca <- prcomp(total_data)
#summary(pca)
new_data = pca$x[,1:5]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
test_ids = data.test$id
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
training_classes = data.train$target
data.train <- subset(data.train,select = -c(target))
training_size = nrow(data.train)
total_data = rbind(data.train, data.test)
col_means = colMeans(total_data,na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
#summary(total_data)
# PCA Stuff
pca <- prcomp(total_data)
#summary(pca)
new_data = pca$x[,1:5]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
test_ids = data.test$id
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
training_classes = data.train$target
data.train <- subset(data.train,select = -c(target))
training_size = nrow(data.train)
total_data = rbind(data.train, data.test)
col_means = colMeans(total_data,na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
#summary(total_data)
# PCA Stuff
pca <- prcomp(total_data)
#summary(pca)
new_data = pca$x[,1:5]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
submission = cbind(id = test_ids, target = pred[,2])
View(submission)
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE)
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
#install.packages('mice')
#library('mice')
#setwd('C:\\Users\\Joshua\\Documents\\GitHub\\B365-Final-Project')
options(scipen = 50)
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
test_ids = data.test$id
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
training_classes = data.train$target
data.train <- subset(data.train,select = -c(target))
training_size = nrow(data.train)
total_data = rbind(data.train, data.test)
col_means = colMeans(total_data,na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
#summary(total_data)
# PCA Stuff
pca <- prcomp(total_data)
#summary(pca)
new_data = pca$x[,1:5]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
submission = cbind(id = test_ids, target = pred[,2])
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
#model = train(training,training_classes,'nb',trControl=trainControl(method='cv',number=10))
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
new_data = pca$x[,1:8]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
submission = cbind(id = test_ids, target = pred[,2])
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
#model = train(training,training_classes,'nb',trControl=trainControl(method='cv',number=10))
new_data = pca$x[,1:16]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
submission = cbind(id = test_ids, target = pred[,2])
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
#model = train(training,training_classes,'nb',trControl=trainControl(method='cv',number=10))
new_data = pca$x[,1:24]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
submission = cbind(id = test_ids, target = pred[,2])
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
#model = train(training,training_classes,'nb',trControl=trainControl(method='cv',number=10))
options(scipen = 50)
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
test_ids = data.test$id
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
training_classes = data.train$target
data.train <- subset(data.train,select = -c(target))
training_size = nrow(data.train)
total_data = rbind(data.train, data.test)
col_means = colMeans(total_data,na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
#summary(total_data)
# PCA Stuff
pca <- prcomp(total_data, scale. = TRUE)
#summary(pca)
new_data = pca$x[,1:16]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
submission = cbind(id = test_ids, target = pred[,2])
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
#model = train(training,training_classes,'nb',trControl=trainControl(method='cv',number=10))
install.packages("matrixStats")
library("matrixStats")
library("matrixStats")
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
test_ids = data.test$id
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
training_classes = data.train$target
data.train <- subset(data.train,select = -c(target))
training_size = nrow(data.train)
total_data = rbind(data.train, data.test)
col_means = colMedians(total_data, na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
#summary(total_data)
# PCA Stuff
pca <- prcomp(total_data, scale. = TRUE)
#summary(pca)
new_data = pca$x[,1:16]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
submission = cbind(id = test_ids, target = pred[,2])
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
install.packages("amelia")
install.packages("Amelia")
library("Amelia")
>>>>>>> d6022379e19da6b8d86036dbe7884671d194272e
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
<<<<<<< HEAD
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
#install.packages('mice')
#library('mice')
setwd('C:\\Users\\Joshua\\Documents\\GitHub\\B365-Final-Project')
#install.packages('mice')
#library('mice')
#setwd('C:\\Users\\Joshua\\Documents\\GitHub\\B365-Final-Project')
library("caret")
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
=======
test_ids = data.test$id
data.test <- subset(data.test,select = -c(id))
data.train <- subset(data.train,select = -c(id))
training_classes = data.train$target
data.train <- subset(data.train,select = -c(target))
training_size = nrow(data.train)
# data.test <- subset(data.test,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
# data.train <- subset(data.train,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
total_data = rbind(data.train, data.test)
summary(total_data)
total_data <- amelia(total_data, m=5, p2s = 1)
total_data = rbind(data.train, data.test)
summary(total_data)
total_data <- amelia(total_data, m=1, p2s = 1)
summary(total_data)
total_data = rbind(data.train, data.test)
summary(total_data)
total_data <- amelia(total_data, idvars = c("ps_ind_14", "NA_count"), m=1, p2s = 1)
summary(total_data)
total_data = rbind(data.train, data.test)
total_data <- amelia(total_data, idvars = c("ps_ind_14", "NA_count", "ps_ind_09_bin"), m=5, p2s = 1)
summary(total_data)
total_data = rbind(data.train, data.test)
total_data <- amelia(total_data, idvars = c("ps_ind_14", "NA_count", "ps_ind_09_bin"), m=3, p2s = 1)
summary(total_data)
data.test <- subset(data.test,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
total_data = rbind(data.train, data.test)
total_data <- amelia(total_data, idvars = c("ps_ind_14", "NA_count", "ps_ind_09_bin"), m=3, p2s = 1)
summary(total_data)
>>>>>>> d6022379e19da6b8d86036dbe7884671d194272e
