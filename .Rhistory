pca <- princomp(A)
screeplot(pca)
# Checking the results with princomp()
pca <- princomp(A)
pca$scores # return new data
########################################################################################
# PCA with prcomp() over Iris data set
?prcomp
data(iris)
pca.data <- iris[,-5] # remove class variable
pca <- prcomp(pca.data) #pca with prcomp()
summary(pca) # importance of principal components
#How many principal components
plot(pca, type = "l")
screeplot(pca)
#newdata
pca$x
summary(pca) # importance of principal components
#How many principal components
plot(pca, type = "l")
screeplot(pca)
#newdata
pca$x
pca$x[1:10,]
pairs(pca$x[,1:2])
pca$x[1:10,]
pca$x[,1:2]
pairs(pca$x[,1:2])
# principal components are linear combinations of the original variables
pca$rotation  #rotation or loadings
# principal components are linear combinations of the original variables
pca$rotation  #rotation or loadings
biplot(pca,scale=0)
data(iris)
pca.data <- iris[,-5] # remove the class variable
pca <- princomp(pca.data) #pca with princomp()
loadings(pca) #loadings
pca$scores[1:5,] #data after transformation
dim(iris)
#adding class variable to transformed data that only contains first two PCs
reduced.iris <- data.frame(pca$scores[,1:2],Species=iris$Species)
dim(reduced.iris)
head(reduced.iris)
pairs(pca$x[,1:2])
#newdata
pca$x
data(iris)
pca.data <- iris[,-5] # remove class variable
pca <- prcomp(pca.data) #pca with prcomp()
summary(pca) # importance of principal components
#How many principal components
plot(pca, type = "l")
screeplot(pca)
#newdata
pca$x
pca$x[1:10,]
screeplot(pca)
#How many principal components
plot(pca, type = "l")
screeplot(pca)
d = fread("https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data")
d.data = d[,-35]
library(data.table)
d = fread("https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data")
d.data = d[,-35]
pca = prcomp(d.data)
summary(pca)
plot(pca, type = "l")
screeplot(pca)
plot(pca$x[,1:2])
plot(pca, type = "l")
screeplot(pca)
#newdata
pca$x
pca$x[1:10,]
pca$x[,1:2]
pca$x[1:10,]
pca$x[,1:2]
pairs(pca$x[,1:2])
plot(pca, type="l")
pairs(pca$x[,1:2])
pairs(pca$rotation[,1:2])
?prcomp
pairs(pca$x[,1:2])
plot(pca, type = "l")
screeplot(pca)
y = pca$x[,1:9]
y
plot(y)
plot(pca, type = "l")
summary(pca)
library(data.table)
d2 = fread("https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data")
d2.data = d2[sample(nrow(d2), 50),]
h = hclust(dist(d2.data[,-35]))
plot(h)
h.cut = cutree(h, k=2)
plot(h.cut)
head(h.cut)
library(data.table)
d2 = fread("https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data")
d2.data = d2[sample(nrow(d2), 50),]
h = hclust(dist(d2.data[,-35]))
plot(h)
h.cut = cutree(h, k=2)
plot(h.cut)
head(h.cut)
h.cut
h
plot(h)
h.new = cbind(h.cut, h$V35)
h.new
h.cut
h$v35
h.new = cbind(h.cut, d2.data$V35)
h.new
h.comparison = cbind(h.cut, d2.data$V35)
g1 = h.comparison[h.comparison == 1]
g1
g1 = h.comparison[h.comparison == 1,]
g1 = sum(h.comparison == 1)
sum(h.comparison == 1)
sum(h.comparison == "g")
sum(h.comparison == "b")
h.comparison
sum(h.comparison == 2)
sum(h.comparison == "g")
sum(h.comparison == "b") #
x = h.comparison == 1
x
x = h.comparison == 1, "g"
x = h.comparison[h.comparison[,1] == 1 & h.comparison[,2] "g"]
x = h.comparison[h.comparison[,1] == 1 & h.comparison[,2] == "g"]
x
length(x)
sum(x==1)
x = h.comparison[h.comparison[,1] == 1 & h.comparison[,2] == "b"]
sum(x == 1) #34
x = h.comparison[h.comparison[,1] == 2 & h.comparison[,2] == "g"]
sum(x == 1) #9
sum(x == 1) #0
x
sum(x == 2) #0
h.pca = prcomp(d2.data)
head(d2.data)
h.pca = prcomp(d2.data[,-35])
h.pca
summary(h.pca)
.pca = prcomp(d2.data[,-35])
d.pca = prcomp(d2.data[,-35])
summary(d.pca)
d.pca = prcomp(d2.data[,-35])
summary(d.pca)
d.reduced = d.pca$x[,1:10]
d.reduced
h.reduced = hclust(dist(d.reduced))
plot(h.reduced)
plot(h)
plot(h.reduced)
h2 = hclust(dist(d.reduced))
plot(h2)
h2.cut = cutree(h2, k=2)
h.comparison = cbind(h.cut, d2.data$V35)
h2.comparison = cbind(h.cut, d2.data$V35)
h2.comparison
h2.comparison = cbind(h2.cut, d2.data$V35)
h2.comparison
d.pca = prcomp(d2.data[,-35])
summary(d.pca)
d.reduced = d.pca$x[,1:10]
h2 = hclust(dist(d.reduced))
plot(h2)
h2.cut = cutree(h2, k=2)
h2.comparison = cbind(h2.cut, d2.data$V35)
h2.comparison
x = h2.comparison[h2.comparison[,1] == 1 & h2.comparison[,2] == "b"]
sum(x == 1) #9
x
h2.comparison
sum(h2.comparison == 1) #Cluster 1 size =
sum(h2.comparison == 2) #Cluster 2 size =
x = h2.comparison[h2.comparison[,1] == 1 & h2.comparison[,2] == "b"]
sum(x == 1) #9
8/39
x = h.comparison[h2.comparison[,1] == 2 & h2.comparison[,2] == "g"]
sum(x == 2) #3
8/39
3/11
x = h2.comparison[h2.comparison[,1] == 1 & h2.comparison[,2] == "b"]
sum(x == 1) #8
8/39
x = h2.comparison[h2.comparison[,1] == 2 & h2.comparison[,2] == "g"]
sum(x == 2) #3
3/11
sum(x == 2) #6
6/11
h2.comparison
sum(h2.comparison == 1) #Cluster 1 size = 39
sum(h2.comparison == 2) #Cluster 2 size = 11
x = h2.comparison[h2.comparison[,1] == 1 & h2.comparison[,2] == "b"]
sum(x == 1) #8
8/39
x = h2.comparison[h2.comparison[,1] == 2 & h2.comparison[,2] == "g"]
sum(x == 2) #6
x = h2.comparison[h2.comparison[,1] == 2 & h2.comparison[,2] == "b"]
sum(x == 2) #6
x = h2.comparison[h2.comparison[,1] == 1 & h2.comparison[,2] == "g"]
sum(x == 1) #8
31/39
d.pca = prcomp(d2.data[,-35])
summary(d.pca)
d.pca$x
d.reduced = d.pca$x[,1:10]
d.reduced
h2 = hclust(dist(d.reduced))
plot(h2)
h2.comparison = cbind(h2.cut, d2.data$V35)
h2.comparison
sum(h2.comparison == 1) #Cluster 1 size = 39
sum(h2.comparison == 2) #Cluster 2 size = 11
x = h2.comparison[h2.comparison[,1] == 1 & h2.comparison[,2] == "g"]
sum(x == 1) #8
x = h2.comparison[h2.comparison[,1] == 1 & h2.comparison[,2] == "b"]
sum(x == 1) #8
8/39
x = h2.comparison[h2.comparison[,1] == 2 & h2.comparison[,2] == "g"]
sum(x == 2) #6
6/11
d.pca = prcomp(d2.data[,-35])
summary(d.pca)
library(data.table)
d2 = fread("https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data")
d2.data = d2[sample(nrow(d2), 50),]
d.pca = prcomp(d2.data[,-35])
summary(d.pca)
d.pca$x
d.reduced = d.pca$x[,1:10]
h2 = hclust(dist(d.reduced))
plot(h2)
h2.cut = cutree(h2, k=2)
h2.comparison = cbind(h2.cut, d2.data$V35)
h2.comparison
sum(h2.comparison == 1) #Cluster 1 size = 39
sum(h2.comparison == 2) #Cluster 2 size = 11
x = h2.comparison[h2.comparison[,1] == 1 & h2.comparison[,2] == "b"]
sum(x == 1) #8
8/39
x = h2.comparison[h2.comparison[,1] == 2 & h2.comparison[,2] == "g"]
sum(x == 2) #6
sum(h2.comparison == 1) #Cluster 1 size = 39
sum(h2.comparison == 2) #Cluster 2 size = 11
.205+.545
.75/2
h2 = hclust(dist(d.reduced), method = "complete")
d2 = fread("https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data")
d2.data = d2[sample(nrow(d2), 50),]
h = hclust(dist(d2.data[,-35]), method = "complete")
plot(h)
h.cut = cutree(h, k=2)
plot(h.cut)
h.comparison = cbind(h.cut, d2.data$V35)
h.comparison
sum(h.comparison == 1) #Cluster 1 size = 43
sum(h.comparison == 2) #Cluster 2 size = 7
h = hclust(dist(d2.data[,-35], method = "euclidean"), method = "complete")
d2 = fread("https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data")
d2.data = d2[sample(nrow(d2), 50),]
h = hclust(dist(d2.data[,-35], method = "euclidean"), method = "complete")
plot(h)
h.cut = cutree(h, k=2)
plot(h.cut)
h.comparison = cbind(h.cut, d2.data$V35)
h.comparison
sum(h.comparison == 1) #Cluster 1 size = 43
sum(h.comparison == 2) #Cluster 2 size = 7
sum(h.comparison == "g") #37
sum(h.comparison == "b") #13
sum(h.comparison == "b") #11
x = h.comparison[h.comparison[,1] == 1 & h.comparison[,2] == "b"]
sum(x == 1) #9
x = h.comparison[h.comparison[,1] == 1 & h.comparison[,2] == "g"]
sum(x == 1) #8
8/20
x = h.comparison[h.comparison[,1] == 2 & h.comparison[,2] == "g"]
sum(x == 2) #3
x = h.comparison[h.comparison[,1] == 2 & h.comparison[,2] == "b"]
sum(x == 2) #g = 27
3/30
8/20
h2 = hclust(dist(d.reduced, method = "euclidean"), method = "complete")
h.comparison
plot(h)
plot(h, main = "2.2.1")
sum(h.comparison == 1) #Cluster 1 size = 20
sum(h.comparison == 2) #Cluster 2 size = 30
sum(h.comparison == "g") #39
sum(h.comparison == "b") #11
x = h.comparison[h.comparison[,1] == 1 & h.comparison[,2] == "g"]
sum(x == 1) #b = 8, g = 12
d.pca = prcomp(d2.data[,-35])
summary(d.pca)
summary(d.pca)
d.reduced = d.pca$x[,1:8]
h2 = hclust(dist(d.reduced, method = "euclidean"), method = "complete")
plot(h2)
plot(h2, main = "2.2.3")
h2.cut = cutree(h2, k=2)
h2.comparison = cbind(h2.cut, d2.data$V35)
h2.comparison
sum(h2.comparison == 1) #Cluster 1 size = 39
sum(h2.comparison == 2) #Cluster 2 size = 11
sum(h.comparison == "g") #39
sum(h.comparison == "b") #11
sum(h2.comparison == "g") #39
sum(h2.comparison == "b") #11
x = h2.comparison[h2.comparison[,1] == 1 & h2.comparison[,2] == "b"]
sum(x == 1) #8
x = h2.comparison[h2.comparison[,1] == 2 & h2.comparison[,2] == "g"]
sum(x == 2) #6
x = h2.comparison[h2.comparison[,1] == 2 & h2.comparison[,2] == "b"]
sum(x == 2) #6
5/36
sum(h2.comparison == 1) #Cluster 1 size = 14
h2.comparison == 1
sum(h2.comparison == 1) #Cluster 1 size = 14
sum(h2.comparison == 2) #Cluster 2 size = 36
x = h2.comparison[h2.comparison[,1] == 1 & h2.comparison[,2] == "b"]
x = h2.comparison[h2.comparison[,1] == 1 & h2.comparison[,2] == "g"]
sum(x == 1) #6
6/14
.429+.139
.568/2
d = fread("https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data")
d.data = d[,-35]
pca = prcomp(d.data)
summary(pca)
plot(pca, type = "l")
plot(pca, type = "l", main = "PC Variance")
plot(h, main = "2.2.1")
plot(h2, main = "2.2.3")
library(data.table)
d = fread("https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data")
d.data = d[,-35]
pca = prcomp(d.data)
summary(pca)
plot(pca, type = "l", main = "PC Variance")
screeplot(pca)
#newdata
pca$x
summary(pca)
pca.reduced = pca$x[,1:18]
pca.reduced
min(1,2)
x = h2.comparison[h2.comparison[,1] == k & h2.comparison[,2] == "g"]
y = h2.comparison[h2.comparison[,1] == k & h2.comparison[,2] == "b"]
x
y
h2.comparison
z = min(sum(x == k), sum(y == k))
err = z/sum(h2.comparison == k)
er
err
z
x = h2.comparison[h2.comparison[,1] == k & h2.comparison[,2] == "g"]
x
h2.comparison
x = h2.comparison[h2.comparison[,1] == 1 & h2.comparison[,2] == "g"]
sum(x == 1) #6
k=1
x = h2.comparison[h2.comparison[,1] == k & h2.comparison[,2] == "g"]
y = h2.comparison[h2.comparison[,1] == k & h2.comparison[,2] == "b"]
z = min(sum(x == k), sum(y == k))
err = z/sum(h2.comparison == k)
err
k=2
x = h2.comparison[h2.comparison[,1] == k & h2.comparison[,2] == "g"]
y = h2.comparison[h2.comparison[,1] == k & h2.comparison[,2] == "b"]
z = min(sum(x == k), sum(y == k))
err = z/sum(h2.comparison == k)
err
kmRes = kmeans(pca.reduced, dist.euclidean, centers = k)
pca.reduced
kmRes = kmeans(pca.reduced, dist.euclidean, centers = k)
kmRes = kmeans(pca.reduced, centers = k)
kmRes
kmRes$cluster
pca.reduced = pca$x[,1:18]
error <- function(data, k){
errors = c(rep(0,k))
for(i in 1:k){
x = h2.comparison[h2.comparison[,1] == k & h2.comparison[,2] == "g"]
y = h2.comparison[h2.comparison[,1] == k & h2.comparison[,2] == "b"]
z = min(sum(x == k), sum(y == k))
errors[i] = z/sum(h2.comparison == k)
}
return(mean(errors))
}
errors = as.data.frame(matrix(0,nrow = 20, ncol = 5))
for(k in 2:5){
errorList = list()
for(j in 1:20){
print(j)
kmRes = kmeans(pca.reduced, centers = k)
newdata = cbind(kmRes$cluster, mydata$V35)
errors[j, k] = error(newdata,k)
}
}
errors
error <- function(data, k){
errorList = c(rep(0,k))
for(i in 1:k){
x = h2.comparison[h2.comparison[,1] == k & h2.comparison[,2] == "g"]
y = h2.comparison[h2.comparison[,1] == k & h2.comparison[,2] == "b"]
z = min(sum(x == k), sum(y == k))
err = z/sum(h2.comparison == k)
print(err)
errorList[i] = err
}
return(mean(errorList))
}
errors = as.data.frame(matrix(0,nrow = 20, ncol = 5))
for(k in 2:5){
errorList = list()
for(j in 1:20){
print(j)
kmRes = kmeans(pca.reduced, centers = k)
newdata = cbind(kmRes$cluster, mydata$V35)
errors[j, k] = error(newdata,k)
}
}
error <- function(data, k){
errorList = c(rep(0,k))
for(i in 1:k){
x = data[data[,1] == k & data[,2] == "g"]
y = data[data[,1] == k & data[,2] == "b"]
z = min(sum(x == k), sum(y == k))
err = z/sum(data == k)
print(err)
errorList[i] = err
}
return(mean(errorList))
}
errors = as.data.frame(matrix(0,nrow = 20, ncol = 5))
for(k in 2:5){
errorList = list()
for(j in 1:20){
print(j)
kmRes = kmeans(pca.reduced, centers = k)
newdata = cbind(kmRes$cluster, mydata$V35)
errors[j, k] = error(newdata,k)
}
}
print(data)
error <- function(data, k){
print(data)
errorList = c(rep(0,k))
for(i in 1:k){
x = data[data[,1] == k & data[,2] == "g"]
y = data[data[,1] == k & data[,2] == "b"]
z = min(sum(x == k), sum(y == k))
err = z/sum(data == k)
errorList[i] = err
}
return(mean(errorList))
}
errors = as.data.frame(matrix(0,nrow = 20, ncol = 5))
for(k in 2:5){
errorList = list()
for(j in 1:20){
print(j)
kmRes = kmeans(pca.reduced, centers = k)
newdata = cbind(kmRes$cluster, mydata$V35)
errors[j, k] = error(newdata,k)
}
}
error <- function(data, k){
errorList = c(rep(0,k))
for(i in 1:k){
x = data[data[,1] == i & data[,2] == "g"]
y = data[data[,1] == i & data[,2] == "b"]
z = min(sum(x == i), sum(y == i))
err = z/sum(data == i)
errorList[i] = err
}
return(mean(errorList))
}
errors = as.data.frame(matrix(0,nrow = 20, ncol = 5))
for(k in 2:5){
errorList = list()
for(j in 1:20){
print(j)
kmRes = kmeans(pca.reduced, centers = k)
newdata = cbind(kmRes$cluster, mydata$V35)
errors[j, k] = error(newdata,k)
}
}
errors
boxplot(errors)
boxplot(errors, main = "PCA Reduced K-means errors")
quickpred(data.test)
library('mice')
quickpred(data.test)
setwd('C:\\Users\\Joshua\\Documents\\GitHub\\B365-Final-Project')
library('mice')
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.test <- subset(data.test,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
quickpred(data.test)
summary(data.test)
data.test = quickpred(data.test)
summary(data.test)
