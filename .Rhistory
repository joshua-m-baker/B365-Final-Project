#Contruct Centroids
# indices <- c(1:nrow(data))
# count = 1
# for (i in sample(indices, k, replace = FALSE)){
#   centroids[count] <- data[i,]
#   count <- count+1
# }
centroids = as.data.frame(matrix(rnorm(k*dimen),nrow = k, ncol = dimen))
ctau= .Machine$integer.max
while(ctau >= tau){
#assign centroids to data
for (i in 1:nrow(data)){
data$centroids[i] <- min.dist(data[i,1:ncol(data)-1], distFun, centroids)
}
#update centroids
old_cent <- centroids
for (i in 1:k){
counter = 0
sum = matrix(0, nrow = 1, ncol = dimen)
for (j in 1:nrow(data)){
if (data[j,]$centroids == i){
counter = counter +1
sum <- sum + centroids[i,]
}
}
centroids[i,] = sum/counter
}
centroid_distances = centroids - old_cent
ctau = (1/k) * sum((centroid_distances)^2)
}
return(centroids)
}
mydata=matrix(rnorm(100*2), ncol=2)
mydata[1:50,1]=mydata[1:50,1]+3
mydata[1:50,2]=mydata[1:50,2]-4
KMean(mydata, Euclidean.Dist, 2, 10)
Euclidean.Dist <- function(matrix1, matrix2){
differences <- matrix1-matrix2
diffsqr = differences * differences
return(sqrt(sum(diffsqr)))
}
min.dist <- function(entry, distFun, centroids){
distance = .Machine$integer.max
index = 1
for (i in 1:nrow(centroids)){
held = distFun(entry, centroids[i,])
if(held < distance){
distance = held
index = i
}
}
return(index)
}
KMean <- function(data, distFun, k, tau){
data <- as.data.frame(data)
dimen = ncol(data)
cbind(data, centroids = NA)
centroids <- as.data.frame(matrix(rnorm(k*dimen), nrow = k , ncol = dimen))
old_cent <- centroids
#Contruct Centroids
# indices <- c(1:nrow(data))
# count = 1
# for (i in sample(indices, k, replace = FALSE)){
#   centroids[count] <- data[i,]
#   count <- count+1
# }
centroids = as.data.frame(matrix(rnorm(k*dimen),nrow = k, ncol = dimen))
ctau= .Machine$integer.max
while(ctau >= tau){
#assign centroids to data
for (i in 1:nrow(data)){
data$centroids[i] <- min.dist(data[i,1:ncol(data)-1], distFun, centroids)
}
#update centroids
old_cent <- centroids
for (i in 1:k){
counter = 0
sum = matrix(0, nrow = 1, ncol = dimen)
for (j in 1:nrow(data)){
if (data[j,]$centroids == i){
counter = counter +1
sum <- sum + centroids[i,]
}
}
centroids[i,] = sum/counter
}
centroid_distances = centroids - old_cent
ctau = (1/k) * sum((centroid_distances)^2)
}
print(data)
return(centroids)
}
mydata=matrix(rnorm(100*2), ncol=2)
mydata[1:50,1]=mydata[1:50,1]+3
mydata[1:50,2]=mydata[1:50,2]-4
KMean(mydata, Euclidean.Dist, 2, 10)
Euclidean.Dist <- function(matrix1, matrix2){
differences <- matrix1-matrix2
diffsqr = differences * differences
return(sqrt(sum(diffsqr)))
}
min.dist <- function(entry, distFun, centroids){
distance = .Machine$integer.max
index = 1
for (i in 1:nrow(centroids)){
held = distFun(entry, centroids[i,])
if(held < distance){
distance = held
index = i
}
}
return(index)
}
KMean <- function(data, distFun, k, tau){
dimen = ncol(data)
cbind(data, centroids = NA)
centroids <- as.data.frame(matrix(rnorm(k*dimen), nrow = k , ncol = dimen))
old_cent <- centroids
#Contruct Centroids
# indices <- c(1:nrow(data))
# count = 1
# for (i in sample(indices, k, replace = FALSE)){
#   centroids[count] <- data[i,]
#   count <- count+1
# }
centroids = as.data.frame(matrix(rnorm(k*dimen),nrow = k, ncol = dimen))
ctau= .Machine$integer.max
while(ctau >= tau){
#assign centroids to data
for (i in 1:nrow(data)){
data$centroids[i] <- min.dist(data[i,1:ncol(data)-1], distFun, centroids)
}
#update centroids
old_cent <- centroids
for (i in 1:k){
counter = 0
sum = matrix(0, nrow = 1, ncol = dimen)
for (j in 1:nrow(data)){
if (data[j,]$centroids == i){
counter = counter +1
sum <- sum + centroids[i,]
}
}
centroids[i,] = sum/counter
}
centroid_distances = centroids - old_cent
ctau = (1/k) * sum((centroid_distances)^2)
}
return(centroids)
}
mydata=matrix(rnorm(100*2), ncol=2)
mydata[1:50,1]=mydata[1:50,1]+3
mydata[1:50,2]=mydata[1:50,2]-4
KMean(as.data.frame(mydata), Euclidean.Dist, 2, 10)
data <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data", header = FALSE)
A <- data[,-length(data)]
A.pca <- prcomp(A)
summary(A.pca)
pairs(A.pca$x[,1:2])
plot(A.pca, type = "l")
setwd("C:/Users/Greg/B365-Final-Project")
setwd('C:\\Users\\Joshua\\Documents\\GitHub\\B365-Final-Project')
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
data.test <- subset(data.test,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
setwd("C:/Users/Greg/B365-Final-Project")
setwd("C:/Users/Greg/B365-Final-Project")
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
data.test <- subset(data.test,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
View(data.test)
View(data.train)
training_classes = data.train[,2]
data.train <- subset(data.train,select = -c(target))
View(data.train)
training_size = length(data.train)
total_data = rbind(data.train, data.test)
pca <- prcomp(total_data)
summary(total_data)
col_means = colMeans(total_data,na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
summary(total_data)
pca <- prcomp(total_data)
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
pca
pca.loadings
summary(pca)
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
training_classes = data.train[,1]
data.train <- subset(data.train,select = -c(target))
training_size = length(data.train)
total_data = rbind(data.train, data.test)
col_means = colMeans(total_data,na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
summary(total_data)
# PCA Stuff
pca <- prcomp(total_data)
summary(pca)
View(data.test)
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
View(data.test)
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
test_ids = data.test$id
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
training_classes = data.train$target
data.train <- subset(data.train,select = -c(target))
training_size = nrow(data.train)
total_data = rbind(data.train, data.test)
col_means = colMeans(total_data,na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
#summary(total_data)
# PCA Stuff
pca <- prcomp(total_data)
#summary(pca)
new_data = pca$x[,1:5]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
test_ids = data.test$id
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
training_classes = data.train$target
data.train <- subset(data.train,select = -c(target))
training_size = nrow(data.train)
total_data = rbind(data.train, data.test)
col_means = colMeans(total_data,na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
#summary(total_data)
# PCA Stuff
pca <- prcomp(total_data)
#summary(pca)
new_data = pca$x[,1:5]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
test_ids = data.test$id
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
training_classes = data.train$target
data.train <- subset(data.train,select = -c(target))
training_size = nrow(data.train)
total_data = rbind(data.train, data.test)
col_means = colMeans(total_data,na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
#summary(total_data)
# PCA Stuff
pca <- prcomp(total_data)
#summary(pca)
new_data = pca$x[,1:5]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
submission = cbind(id = test_ids, target = pred[,2])
View(submission)
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE)
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
#install.packages('mice')
#library('mice')
#setwd('C:\\Users\\Joshua\\Documents\\GitHub\\B365-Final-Project')
options(scipen = 50)
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
test_ids = data.test$id
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
training_classes = data.train$target
data.train <- subset(data.train,select = -c(target))
training_size = nrow(data.train)
total_data = rbind(data.train, data.test)
col_means = colMeans(total_data,na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
#summary(total_data)
# PCA Stuff
pca <- prcomp(total_data)
#summary(pca)
new_data = pca$x[,1:5]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
submission = cbind(id = test_ids, target = pred[,2])
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
#model = train(training,training_classes,'nb',trControl=trainControl(method='cv',number=10))
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
new_data = pca$x[,1:8]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
submission = cbind(id = test_ids, target = pred[,2])
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
#model = train(training,training_classes,'nb',trControl=trainControl(method='cv',number=10))
new_data = pca$x[,1:16]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
submission = cbind(id = test_ids, target = pred[,2])
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
#model = train(training,training_classes,'nb',trControl=trainControl(method='cv',number=10))
new_data = pca$x[,1:24]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
submission = cbind(id = test_ids, target = pred[,2])
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
#model = train(training,training_classes,'nb',trControl=trainControl(method='cv',number=10))
options(scipen = 50)
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
test_ids = data.test$id
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
training_classes = data.train$target
data.train <- subset(data.train,select = -c(target))
training_size = nrow(data.train)
total_data = rbind(data.train, data.test)
col_means = colMeans(total_data,na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
#summary(total_data)
# PCA Stuff
pca <- prcomp(total_data, scale. = TRUE)
#summary(pca)
new_data = pca$x[,1:16]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
submission = cbind(id = test_ids, target = pred[,2])
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
#model = train(training,training_classes,'nb',trControl=trainControl(method='cv',number=10))
install.packages("matrixStats")
library("matrixStats")
library("matrixStats")
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
test_ids = data.test$id
data.test <- subset(data.test,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(id,ps_car_03_cat,ps_car_05_cat,ps_reg_03))
training_classes = data.train$target
data.train <- subset(data.train,select = -c(target))
training_size = nrow(data.train)
total_data = rbind(data.train, data.test)
col_means = colMedians(total_data, na.rm = TRUE)
for(i in 1:ncol(total_data)){
total_data[is.na(total_data[,i]), i] <- col_means[i]
}
#summary(total_data)
# PCA Stuff
pca <- prcomp(total_data, scale. = TRUE)
#summary(pca)
new_data = pca$x[,1:16]
training = as.data.frame(new_data[1:training_size,])
test = new_data[(training_size+1):nrow(new_data),]
d2 = cbind(training, training_classes)
library('e1071')
model = naiveBayes(training_classes~.,data=training)
pred = predict(model, test,"raw")
pred
pred[,2]
submission = cbind(id = test_ids, target = pred[,2])
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
write.table(submission, file="submission.csv", row.names = FALSE, col.names = TRUE, sep=",")
install.packages("amelia")
install.packages("Amelia")
library("Amelia")
data.train <- read.csv("train.csv", header = TRUE,na.strings = "-1" )
data.test <- read.csv("test.csv", header = TRUE,na.strings = "-1")
data.train[data.train<0] = NA
data.test[data.test<0] = NA
data.test = cbind(data.test,NA_count = rowSums(is.na(data.test)))
data.train = cbind(data.train,NA_count = rowSums(is.na(data.train)))
test_ids = data.test$id
data.test <- subset(data.test,select = -c(id))
data.train <- subset(data.train,select = -c(id))
training_classes = data.train$target
data.train <- subset(data.train,select = -c(target))
training_size = nrow(data.train)
# data.test <- subset(data.test,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
# data.train <- subset(data.train,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
total_data = rbind(data.train, data.test)
summary(total_data)
total_data <- amelia(total_data, m=5, p2s = 1)
total_data = rbind(data.train, data.test)
summary(total_data)
total_data <- amelia(total_data, m=1, p2s = 1)
summary(total_data)
total_data = rbind(data.train, data.test)
summary(total_data)
total_data <- amelia(total_data, idvars = c("ps_ind_14", "NA_count"), m=1, p2s = 1)
summary(total_data)
total_data = rbind(data.train, data.test)
total_data <- amelia(total_data, idvars = c("ps_ind_14", "NA_count", "ps_ind_09_bin"), m=5, p2s = 1)
summary(total_data)
total_data = rbind(data.train, data.test)
total_data <- amelia(total_data, idvars = c("ps_ind_14", "NA_count", "ps_ind_09_bin"), m=3, p2s = 1)
summary(total_data)
data.test <- subset(data.test,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
data.train <- subset(data.train,select = -c(ps_car_03_cat,ps_car_05_cat,ps_reg_03))
total_data = rbind(data.train, data.test)
total_data <- amelia(total_data, idvars = c("ps_ind_14", "NA_count", "ps_ind_09_bin"), m=3, p2s = 1)
summary(total_data)
